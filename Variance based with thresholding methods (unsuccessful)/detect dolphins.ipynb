{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe1c40fc-faf5-4242-a716-94af723c0d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dauphins détectés aux instants: [68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_dolphins(video_path, threshold= 5.3e7 , fps =30):\n",
    "    # Ouvrir la vidéo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur lors de l'ouverture de la vidéo.\")\n",
    "        return\n",
    "\n",
    "    frames = []\n",
    "    instants_dauphins = []\n",
    "\n",
    "    frame_number = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convertir en niveau de gris pour simplifier l'analyse\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Si nous avons plus de 10 images, supprimer la plus ancienne\n",
    "        if len(frames) > 10:\n",
    "            frames.pop(0)\n",
    "\n",
    "        # Comparer l'image actuelle avec les dix précédentes\n",
    "        for prev_frame in frames:\n",
    "            diff = cv2.absdiff(gray, prev_frame)\n",
    "            diff_sum = np.sum(diff)\n",
    "            \n",
    "            if diff_sum > threshold:\n",
    "                instants_dauphins.append(frame_number//fps)\n",
    "                break\n",
    "\n",
    "        frames.append(gray)\n",
    "        frame_number += 1\n",
    "\n",
    "    cap.release()\n",
    "    return instants_dauphins\n",
    "\n",
    "video_path = \"/home/alexis/Desktop/short1.mp4\"\n",
    "instants = detect_dolphins(video_path)\n",
    "print(\"Dauphins détectés aux instants:\", instants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595985d-65d3-4373-84a6-d5e8a77f6cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20ff89fd-5fc4-402d-9054-5c6eca0be8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Start         End\n",
      "0   91.224467   97.430667\n",
      "1  102.502400  105.905800\n",
      "2  398.131067  400.066333\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "def find_dolphins_in(video_path, duration_threshold = 1.71, contour_threshold=1850):\n",
    "    \"\"\"\n",
    "    Looks for big moving objects.\n",
    "\n",
    "    :param video_path: Path to the video file\n",
    "    :param duration_threshold: Duration in seconds to qualify as motion\n",
    "    :param contour_threshold : threshold for the size of the object we want to detect\n",
    "    :return: The motion event times\n",
    "    \"\"\"\n",
    "  \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Get the frames per second (fps) of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Initialize background frame for background subtraction\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video\")\n",
    "        cap.release()\n",
    "        exit()\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # DataFrame to store motion data\n",
    "    motion_list = [None, None]\n",
    "    motion_times = []\n",
    "    rows_list = []  # list to collect dictionaries for creating DataFrame\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        # Read frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit loop if no more frames are available\n",
    "\n",
    "        motion = 0\n",
    "\n",
    "        # Preprocess the frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "        # Compute the absolute difference between the current frame and background frame\n",
    "        diff_frame = cv2.absdiff(gray_frame, gray)\n",
    "\n",
    "        # Apply thresholding to get the foreground mask\n",
    "        thresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh_frame = cv2.dilate(thresh_frame, None, iterations=2)\n",
    "\n",
    "        # Find contours of moving objects\n",
    "        cnts, _ = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in cnts:\n",
    "            if cv2.contourArea(contour) < contour_threshold:\n",
    "                continue\n",
    "            motion = 1\n",
    "\n",
    "        # Append status of motion\n",
    "        motion_list.append(motion)\n",
    "        motion_list = motion_list[-2:]\n",
    "\n",
    "        # Append Start time of motion\n",
    "        if motion_list[-1] == 1 and motion_list[-2] == 0:\n",
    "            motion_times.append(frame_count / fps)\n",
    "\n",
    "        # Append End time of motion\n",
    "        if motion_list[-1] == 0 and motion_list[-2] == 1:\n",
    "            motion_times.append(frame_count / fps)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    for i in range(0, len(motion_times)-1, 2):\n",
    "        duration = motion_times[i + 1] - motion_times[i]\n",
    "        if duration > duration_threshold:\n",
    "            rows_list.append({\"Start\": motion_times[i], \"End\": motion_times[i + 1]})\n",
    "\n",
    "    if rows_list:\n",
    "        df = pd.concat([pd.DataFrame([row]) for row in rows_list], ignore_index=True)\n",
    "    else:\n",
    "        print(\"No data to concatenate. Returning an empty DataFrame.\")\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    # Release video capture object\n",
    "    cap.release()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "video_path = \"/home/alexis/Desktop/short.mp4\"\n",
    "motion_df = find_dolphins_in(video_path)\n",
    "print(motion_df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# a faire : tester en divisant le contour threshold npar 16 et regarder les correspondances de timing pour short.\n",
    "# mettre lextrait video dans un fichier separ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint, skipping files: ['short.mp4']\n",
      "Skipping already processed file: short.mp4\n",
      "Processing file: Exp_12_Oct_2023_1245_cam_all.mp4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/alexis/Documents/GitHub/Dolphins internship/Image_detection/detect dolphins.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m directory_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/alexis/Desktop/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m processed_videos \u001b[39m=\u001b[39m process_all_videos(directory_path, find_dolphins_in)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Print the results for each video\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m video_name, df \u001b[39min\u001b[39;00m processed_videos:\n",
      "\u001b[1;32m/home/alexis/Documents/GitHub/Dolphins internship/Image_detection/detect dolphins.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing file: \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m df \u001b[39m=\u001b[39m processing_function(file_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m all_dfs\u001b[39m.\u001b[39mappend((filename, df))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Update checkpoint file\u001b[39;00m\n",
      "\u001b[1;32m/home/alexis/Documents/GitHub/Dolphins internship/Image_detection/detect dolphins.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m         rows_list\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mStart\u001b[39m\u001b[39m\"\u001b[39m: motion_times[i], \u001b[39m\"\u001b[39m\u001b[39mEnd\u001b[39m\u001b[39m\"\u001b[39m: motion_times[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]})\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# Create DataFrame from the list of dictionaries\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([pd\u001b[39m.\u001b[39;49mDataFrame([row]) \u001b[39mfor\u001b[39;49;00m row \u001b[39min\u001b[39;49;00m rows_list], ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m# Release video capture object\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#X10sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    383\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    384\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    385\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    386\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    387\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    388\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    389\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    390\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_integrity \u001b[39m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    445\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_all_videos(directory_path, processing_function, checkpoint_file=\"checkpoint.csv\"):\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(\"Directory does not exist:\", directory_path)\n",
    "        return\n",
    "\n",
    "    # Try to load progress from the checkpoint file\n",
    "    processed_videos = []\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        processed_videos = pd.read_csv(checkpoint_file)['Filename'].tolist()\n",
    "        print(\"Resuming from checkpoint, skipping files:\", processed_videos)\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path) and file_path.endswith(\".mp4\"):\n",
    "            if filename in processed_videos:\n",
    "                print(f\"Skipping already processed file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            df = processing_function(file_path)\n",
    "            all_dfs.append((filename, df))\n",
    "\n",
    "            # Update checkpoint file\n",
    "            processed_videos.append(filename)\n",
    "            pd.DataFrame({'Filename': processed_videos}).to_csv(checkpoint_file, index=False)\n",
    "\n",
    "    return all_dfs\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"/home/alexis/Desktop/\"\n",
    "processed_videos = process_all_videos(directory_path, find_dolphins_in)\n",
    "\n",
    "# Print the results for each video\n",
    "for video_name, df in processed_videos:\n",
    "    print(f\"Results for {video_name}:\")\n",
    "    if df is not None and not df.empty:\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"No data returned or DataFrame is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7839d-49a6-4ece-b100-94b3fc37d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "!pip install -qr requirements.txt  # install\n",
    "import torch\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/alexis/Documents/GitHub/Dolphins/Image_detection/classify/predict.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python classify/predict.py --source /home/alexis/Desktop/short.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "043a6fad-8431-40a6-ab49-b2aabbab5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: short1.mp4\n",
      "Processing file: testvidéo.mp4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/alexis/Documents/GitHub/Dolphins internship/Image_detection/detect dolphins.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_results\u001b[39m.\u001b[39mto_csv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_file, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m processor \u001b[39m=\u001b[39m VideoProcessor(\u001b[39m\"\u001b[39m\u001b[39m/home/alexis/Desktop/video\u001b[39m\u001b[39m\"\u001b[39m, find_dolphins_in)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m processor\u001b[39m.\u001b[39;49mprocess_videos()\n",
      "\u001b[1;32m/home/alexis/Documents/GitHub/Dolphins internship/Image_detection/detect dolphins.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(file_path) \u001b[39mand\u001b[39;00m file_path\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.mp4\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_been_processed(filename):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing file: \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessing_function(file_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_results(filename, df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Final update to results file\u001b[39;00m\n",
      "\u001b[1;32m/home/alexis/Documents/GitHub/Dolphins internship/Image_detection/detect dolphins.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m         rows_list\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mStart\u001b[39m\u001b[39m\"\u001b[39m: motion_times[i], \u001b[39m\"\u001b[39m\u001b[39mEnd\u001b[39m\u001b[39m\"\u001b[39m: motion_times[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]})\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# Create DataFrame from the list of dictionaries\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([pd\u001b[39m.\u001b[39;49mDataFrame([row]) \u001b[39mfor\u001b[39;49;00m row \u001b[39min\u001b[39;49;00m rows_list], ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m# Release video capture object\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/GitHub/Dolphins%20internship/Image_detection/detect%20dolphins.ipynb#W2sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    383\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    384\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    385\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    386\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    387\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    388\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    389\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    390\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_integrity \u001b[39m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    445\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, directory_path, processing_function, results_file=\"processed_results.csv\"):\n",
    "        self.directory_path = directory_path\n",
    "        self.processing_function = processing_function\n",
    "        self.results_file = results_file\n",
    "        self.all_results = self._load_results()\n",
    "\n",
    "    def _load_results(self):\n",
    "        if os.path.exists(self.results_file):\n",
    "            return pd.read_csv(self.results_file)\n",
    "        else:\n",
    "            return pd.DataFrame(columns=['Filename', 'Data'])\n",
    "\n",
    "    def has_been_processed(self, filename):\n",
    "        return filename in self.all_results['Filename'].values\n",
    "\n",
    "    def process_videos(self):\n",
    "        for filename in os.listdir(self.directory_path):\n",
    "            file_path = os.path.join(self.directory_path, filename)\n",
    "            if os.path.isfile(file_path) and file_path.endswith(\".mp4\") and not self.has_been_processed(filename):\n",
    "                print(f\"Processing file: {filename}\")\n",
    "                df = self.processing_function(file_path)\n",
    "                self._update_results(filename, df)\n",
    "\n",
    "        # Final update to results file\n",
    "        self._write_results()\n",
    "\n",
    "    def _update_results(self, filename, df):\n",
    "        if df is not None and not df.empty:\n",
    "            df['Filename'] = filename\n",
    "            self.all_results = pd.concat([self.all_results, df], axis=0)\n",
    "\n",
    "    def _write_results(self):\n",
    "        self.all_results.to_csv(self.results_file, index=False)\n",
    "\n",
    "processor = VideoProcessor(\"/home/alexis/Desktop/video\", find_dolphins_in)\n",
    "processor.process_videos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: short.mp4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14122/1077511327.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdirectory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/alexis/Desktop/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprocess_all_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_dolphins_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14122/1077511327.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(directory_path, processing_function, results_file)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# Update the results file periodically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_all_videos(directory_path, processing_function, results_file=\"processed_results.csv\"):\n",
    "    if not os.path.exists(results_file):\n",
    "        all_results = pd.DataFrame(columns=['Filename', 'Data'])\n",
    "    else:\n",
    "        all_results = pd.read_csv(results_file)\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path) and file_path.endswith(\".mp4\") and filename not in all_results['Filename'].tolist():\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            df = processing_function(file_path)\n",
    "\n",
    "            if df is not None and not df.empty:\n",
    "                df['Filename'] = filename\n",
    "                all_results = all_results.append(df, ignore_index=True)\n",
    "\n",
    "                # Update the results file periodically\n",
    "                all_results.to_csv(results_file, index=False)\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "# Usage\n",
    "directory_path = \"/home/alexis/Desktop/\"\n",
    "process_all_videos(directory_path, find_dolphins_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439c1c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0, j = 0\n",
      "i = 1, j = 0\n",
      "i = 2, j = 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):  # Boucle extérieure\n",
    "    for j in range(3):  # Boucle intérieure\n",
    "        if j == 1:\n",
    "            break\n",
    "        print(f\"i = {i}, j = {j}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
